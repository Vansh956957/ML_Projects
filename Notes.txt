Steps:
A. EDA : This is the method where we visualize (not graphically, but imaginariliy with help of graph) the data and try to
         figure out if there is any relationship in each variable with itself as well as with respect to other.
B. Data Preprocessing : 

A. EDA 

Import Data, 
Split to train, test.
do feature engineeing.

1. Define the data types of each coloumns and divide them on the basis of that.
e.g. Categorical Data and continious data.
* Nominal
* Ordinal
* Interval
* Ratio

| Feature       | Nominal             | Ordinal                  |
| ------------- | ------------------- | ------------------------ |
| Order exists? | ❌ No                | ✅ Yes                    |
| Examples      | Gender, City, Color | Ratings, Education level |
| Can you rank? | ❌                   | ✅                        |



| Feature                        | Ordinal                  | Interval          |
| ------------------------------ | ------------------------ | ----------------- |
| Has order?                     | ✅                        | ✅                 |
| Equal distance between values? | ❌                        | ✅                 |
| Can do arithmetic?             | ❌                        | ✅                 |
| Example                        | Rating scale (1–5 stars) | Temperature in °C |

2. For Numerical distrubution instead of visualizing in set, as can be done in case of categorical.
   visualize in terms of single Featue at a time.
   
   e.g. Independent Variable (Numerical)
    There are 4 features that are Numerical: These features have numerical values :
    (ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term)
    Firstly, let’s look at the Applicant income distribution:

3. Try to relate from the plot what can be noticed, like if there is a dispairity in plot of income range that 
   may be due to some reason. if you cant predict actual reason try to figure out using other columns available 
   and try to link them. like education level may differ the salary, try to plot them both side by side to comapare
   as dependent graph.
   

4. Do Univariate Analysis. This will create a hypothesis on our data.
   Do Bivariate Analysis. Now test the old hypothesis with the newly fonund Hypothesis if it matches  or not with respect to Target VARIABLE.
   DO visualize numerical independent variables with respect to target variable.

5. Correlation matrix



B. Data Preprocessing
   1. Missing values in Training Dataset
   * For numerical variables: imputation using mean or median
   * For categorical variables: imputation using mode.
   NOTE: inplace=True is depreciated use the standard assignment method only
   2. Missing values in test Dataset
   **Note: ** We need to replace the missing values in Test set using the mode/median/mean of the Training set,
     not from the Test set. Likewise, if you remove values above some threshold in the test case, make sure that the 
     threshold is derived from the training and not test set. Make sure to calculate the mean (or any other metrics)
     only on the train data to avoid data leakage to your test set.
   3. IF the data (lets say train['Loan_AMount']) is Right Skewed. we need to make it into normalized form to do any form of 
      numerical computation while model training. i.e. Gaussian Curve. For this use Log Transformation method to normalize the curve.
      train['LoanAmount_log'] = np.log(train['LoanAmount'])


   